{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/max2000777/Traitement-de-la-langue-naturelle/blob/main/MIDS_NLP_TP2_Knn_with_matrices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document classification using the K-NN algorithm and tensorial operations\n",
        "\n",
        "**Copiez ce notebook et mettez votre nom dans le nom de la copie**\n",
        "\n",
        "A rendre par mail marie.candito@gmail.com, avant le **9 février minuit**, avec comme objet du mail :  **MIDS TP2**\n",
        "\n",
        "\n",
        "The aim of this lab is to implement the K-NN algorithm using **tensors**, resulting in **faster** computation of the similarities (or distances) between a document to classify and all the labeled documents."
      ],
      "metadata": {
        "id": "-zfBHWnuuXRV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset download\n",
        "\n",
        "The « reuters21578 » collection is a famous set of documents in English, associated to 0, 1 or n classes (« topics »). We provide a sub-set of this corpus, in which we made sure to have a single gold class for each document (to perform monolabel multiclass classification):\n",
        "\n",
        "More precisely:\n",
        "- train = medium.train.examples = 2000 documents with their gold class\n",
        "- dev = medium.dev.examples \t= 200 documents with gold class\n",
        "o\twhich you will use to test and evaluate the algorithm\n",
        "\n",
        "- Document representation: Documents are represented using BOW vectors, in which the numbers of occurrences word forms have been divided by the total number of tokens in the document .\n",
        "- Format: But NB, the provided *.examples files only contain the components with non-null values, identified using the word form itself instead of an integer position in the vector space.\n",
        "- Vocabulary: the total vocabulary is the union of all features (words) in all training documents.\n",
        "- \"Unknown words\": when applying the K-NN to an input document, its features (words) that are not in the training documents will just be ignored\n",
        "\n",
        "Two smaller train and test files are provided in order to test your program more rapidly while programming.\n"
      ],
      "metadata": {
        "id": "SyY6s1fmyD1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "\n",
        "if not os.path.exists('./reuters-examples/'):\n",
        "  !pip install wget\n",
        "  import wget\n",
        "\n",
        "  # The URL for the dataset tar file\n",
        "  url = 'http://www.linguist.univ-paris-diderot.fr/~mcandito/divers/reuters-examples.zip'\n",
        "\n",
        "\n",
        "  if not os.path.exists('./reuteurs-examples.zip'):\n",
        "    print('Downloading dataset')\n",
        "    wget.download(url, './reuters-examples.zip')\n",
        "    !unzip ./reuters-examples.zip\n",
        "if not os.path.exists('./reuters-examples/small.dev.examples'):\n",
        "  print(\"pb\")\n"
      ],
      "metadata": {
        "id": "YBwmDcA7vJT6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the dataset"
      ],
      "metadata": {
        "id": "67nW3pVsy6zK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Examples:\n",
        "    \"\"\"\n",
        "    a batch of examples:\n",
        "    One example is\n",
        "    - a BOW vector represented as a python dictionary, for features with non-null values only\n",
        "    - a gold class\n",
        "\n",
        "    dict_vectors = list of dictionary BOW vector\n",
        "    gold_classes = list of gold classes\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.gold_classes = []\n",
        "        self.dict_vectors = []\n",
        "\n",
        "def read_examples(infile):\n",
        "    \"\"\" Reads a .examples file and returns an Examples instance.\n",
        "    \"\"\"\n",
        "\n",
        "    stream = open(infile)\n",
        "    examples = Examples()\n",
        "    dict_vector = None\n",
        "    while 1:\n",
        "        line = stream.readline()\n",
        "        if not line:\n",
        "            break\n",
        "        line = line[0:-1]\n",
        "        if line.startswith(\"EXAMPLE_NB\"):\n",
        "            if dict_vector != None:\n",
        "                examples.dict_vectors.append(dict_vector)\n",
        "            dict_vector = {}\n",
        "            cols = line.split('\\t')\n",
        "            gold_class = cols[3]\n",
        "            examples.gold_classes.append(gold_class)\n",
        "        elif line:# and dict_vector != None:\n",
        "            (wordform, val) = line.split('\\t')\n",
        "            dict_vector[wordform] = float(val)\n",
        "\n",
        "    if dict_vector != None:\n",
        "        examples.dict_vectors.append(dict_vector)\n",
        "    return examples\n"
      ],
      "metadata": {
        "id": "Tqdy9u7NujWV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_examples = read_examples('./reuters-examples/medium.train.examples')\n",
        "#dev_examples = read_examples('./reuters-examples/medium.dev.examples')\n",
        "\n",
        "train_examples = read_examples('./reuters-examples/small.train.examples')\n",
        "dev_examples = read_examples(\"./reuters-examples/small.dev.examples\")\n",
        "\n"
      ],
      "metadata": {
        "id": "aEV0iGAVzLKY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for element in train_examples.dict_vectors[0]:\n",
        "  print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix2_5GG4ZOd1",
        "outputId": "dc1d5a2c-8482-4d2c-f729-81ecc793a6ad"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "still\n",
            "its\n",
            "also\n",
            "to\n",
            "total\n",
            "has\n",
            "oct\n",
            "march\n",
            "not\n",
            "february\n",
            "aug\n",
            "ports\n",
            "bahia\n",
            "crop\n",
            "are\n",
            "year\n",
            "dlrs\n",
            "said\n",
            "new\n",
            "be\n",
            "sold\n",
            "york\n",
            "on\n",
            "against\n",
            "times\n",
            "april\n",
            "sept\n",
            "smith\n",
            "cocoa\n",
            "would\n",
            "there\n",
            "sales\n",
            "july\n",
            "with\n",
            "were\n",
            "dec\n",
            "and\n",
            "comissaria\n",
            "it\n",
            "an\n",
            "as\n",
            "at\n",
            "in\n",
            "bags\n",
            "may\n",
            "a\n",
            "june\n",
            "the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO 1: build word <=> indices correspondance"
      ],
      "metadata": {
        "id": "qtZLaK2izmyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO\n",
        "#fonctions du TP1\n",
        "def get_vocab(documents):\n",
        "    w2id = {}\n",
        "    id2w = []\n",
        "    id=0\n",
        "    for ligne in documents:\n",
        "      for token in ligne:\n",
        "        if str(token) not in w2id:\n",
        "          w2id[str(token)]=id;\n",
        "          id+=1;\n",
        "          id2w.append(str(token))\n",
        "    return (w2id, id2w)\n",
        "\n",
        "w2i,i2w = get_vocab(train_examples.dict_vectors)\n",
        "print(w2i)\n",
        "print(f\"Vocabulary size : {len(i2w)}\")\n"
      ],
      "metadata": {
        "id": "v5WY-aY3zz6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "949c6985-8e4c-487c-9da8-915df00fe37f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'still': 0, 'its': 1, 'also': 2, 'to': 3, 'total': 4, 'has': 5, 'oct': 6, 'march': 7, 'not': 8, 'february': 9, 'aug': 10, 'ports': 11, 'bahia': 12, 'crop': 13, 'are': 14, 'year': 15, 'dlrs': 16, 'said': 17, 'new': 18, 'be': 19, 'sold': 20, 'york': 21, 'on': 22, 'against': 23, 'times': 24, 'april': 25, 'sept': 26, 'smith': 27, 'cocoa': 28, 'would': 29, 'there': 30, 'sales': 31, 'july': 32, 'with': 33, 'were': 34, 'dec': 35, 'and': 36, 'comissaria': 37, 'it': 38, 'an': 39, 'as': 40, 'at': 41, 'in': 42, 'bags': 43, 'may': 44, 'a': 45, 'june': 46, 'the': 47, 'from': 48, 'shares': 49, 'company': 50, 'five': 51, 'common': 52, 'stock': 53, 'terminal': 54, 'computer': 55, 'warrants': 56, 'price': 57, 'qtr': 58, 'vs': 59, 'net': 60, 'shr': 61, 'cts': 62, 'or': 63, 'oper': 64, 'profit': 65, 'six': 66}\n",
            "Vocabulary size : 67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO2 : Turn training set and test set into matrices\n",
        "\n",
        "Represent the T=2000 training examples [vector, gold_class] using two structures:\n",
        "-\tX_train: a T x V matrix (ndarray), whose i-th row is the vector for the i-th example\n",
        "-\tY_train: a vector of size T, for the gold classes of the T examples (actually it can be a plain python list for now).\n",
        "\n",
        "Similarly, represent the dev data as X_dev and Y_dev."
      ],
      "metadata": {
        "id": "hZ6EHxshz3oQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.zeros((3,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjzjepa_cHfR",
        "outputId": "0dbcded8-025e-41d0-bdf8-759e03458e80"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_matrices(examples, w2i):\n",
        "  \"\"\" examples = instance of Examples\n",
        "      w2i : word to index dictionary\n",
        "  \"\"\"\n",
        "#   TODO\n",
        "# Tips : start by building an X matrix with desired shape, filled with zeros,\n",
        "#        and while looping over the examples, you can assign the non-null cells\n",
        "  X = np.zeros((len(examples.dict_vectors),len(w2i)))\n",
        "  for i in range(0,len(examples.dict_vectors))  :\n",
        "    for mot in examples.dict_vectors[i] :\n",
        "      if mot in w2i:\n",
        "        X[i,w2i[mot]]=examples.dict_vectors[i][mot]\n",
        "  Y = examples.gold_classes\n",
        "  return (X, Y)\n",
        "\n",
        "# Organize the data into two matrices for document vectors\n",
        "#                   and two lists for the gold classes\n",
        "(X_train, Y_train) = build_matrices(train_examples, w2i)\n",
        "(X_dev, Y_dev) = build_matrices(dev_examples, w2i)\n",
        "print(f\"Training matrix has shape {X_train.shape}\")\n",
        "print(f\" Testing matrix has shape {X_dev.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWJQ6GfN0BJb",
        "outputId": "934a5bae-1847-4be7-92ee-b6482a08642c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training matrix has shape (5, 67)\n",
            " Testing matrix has shape (3, 67)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO3 : K-NN classification:\n",
        "- add the relevant methods to the K-NN class below to perform K-NN classification and its evaluation.\n",
        "- **CONSTRAINT** : use matrix operations to compute the cosines of each row in X_dev with each row in X_train\n",
        "  - shape will be (nb_test, nb_train)\n",
        "  - no loop over rows nor columns!\n",
        "- predict a class for each of the dev examples, using the train examples and K-NN algorithm, using **cosine** to identify the neighbors.\n",
        "- **Evaluation**: Compute and print the resulting accuracy (percentage of dev examples for which the predicted class is the correct one)\n",
        "- The optimal value of K is unknown, all you can do is test some k values and choose the best one (cf. methodology in machine learning : this is “tuning the hyperparameters”)\n"
      ],
      "metadata": {
        "id": "PdAs_KkL0w-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class KNN:\n",
        "    \"\"\"\n",
        "    K-NN for document classification (multiclass)\n",
        "\n",
        "    members =\n",
        "\n",
        "    X_train = matrix of training example vectors\n",
        "    Y_train = list of corresponding gold classes\n",
        "\n",
        "    K = maximum number of neighbors to consider\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, X, Y, K=1, verbose=False):\n",
        "        self.X_train = X   # (nbexamples, d)\n",
        "        self.Y_train = Y   # list of corresponding gold classes\n",
        "\n",
        "        # nb neighbors to consider\n",
        "        self.K = K\n",
        "\n",
        "        self.verbose = verbose\n",
        "    def predict_and_evaluate_on_set(self,X,Y):\n",
        "        Anorm=self.X_train/np.linalg.norm(self.X_train,axis=1).reshape(self.X_train.shape[0],1)\n",
        "        Bnorm=X/np.linalg.norm(X,axis=1).reshape(X.shape[0],1)\n",
        "        MatriceCos=Anorm @ Bnorm.T\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s7FBvIJNue3x"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NB of NEIGHBORS\n",
        "\n",
        "K=5\n",
        "\n",
        "verbose = True\n",
        "\n",
        "myclassifier = KNN(X = X_train,\n",
        "                   Y = Y_train,\n",
        "                   K = K,\n",
        "                   verbose=verbose)\n",
        "\n",
        "#print(\"Evaluating on dev set...\")\n",
        "accuracies = myclassifier.predict_and_evaluate_on_set(X_dev, Y_dev)\n",
        "\n"
      ],
      "metadata": {
        "id": "Gc6mSzKQ3Ik8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b764656-0f95-4266-8865-1183fe739f92"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.1864542  0.         0.18749253]\n",
            " [0.30658331 0.009787   0.08808303]\n",
            " [0.25518441 0.01176674 0.24710158]\n",
            " [0.05080005 0.70624201 0.22135944]\n",
            " [0.01133659 0.66805963 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Efficiency tips:\n",
        "\n",
        "If needed, improve your algorithm:\n",
        "- don't recompute the training norms for all test example\n",
        "- identify which steps are shared for all possible K values as opposed to steps that depend on K.\n",
        "  - you could make your K-NN work for all values from k=1 to k=K, sharing steps not depending on k, and output a list of K accuracies, for k=1, k=2 .... k=K\n"
      ],
      "metadata": {
        "id": "iuCSlv5z38GW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6\tExpected results\n",
        "When using the small corpus (train / dev), here is the expected cos_matrix and the accuracies for a few k values:\n",
        "\n",
        "Matrix of cosine similarities (rows = test, columns = train):\n",
        "\n",
        "[[0.1864542  0.30658331 0.25518441 0.05080005 0.01133659]\n",
        "\n",
        " [0.         0.009787   0.01176674 0.70624201 0.66805963]\n",
        "\n",
        " [0.18749253 0.08808303 0.24710158 0.22135944 0.        ]]\n",
        "\n",
        "ACCURACY FOR K =  1 = 100.00 (3 / 3) (use_weight = False)\n",
        "\n",
        "ACCURACY FOR K =  2 = 66.67 (2 / 3) (use_weight = False)\n",
        "\n",
        "ACCURACY FOR K =  3 = 66.67 (2 / 3) (use_weight = False)\n",
        "\n",
        "\n",
        "On medium, here are the expected results for the first k values:\n",
        "ACCURACY FOR K =  1 = 78.50 (157 / 200) (use_weight = False)\n",
        "\n",
        "ACCURACY FOR K =  2 = 76.00 (152 / 200) (use_weight = False)\n",
        "\n",
        "ACCURACY FOR K =  3 = 77.50 (155 / 200) (use_weight = False)\n",
        "\n",
        "ACCURACY FOR K =  4 = 81.00 (162 / 200) (use_weight = False)\n",
        "\n",
        "ACCURACY FOR K =  5 = 79.50 (159 / 200) (use_weight = False)\n",
        "\n",
        "**NB**: It is ok even if you have not exactly the same results, but if accuracy is close to these values. Results may vary a little depending on the prediction in case of ties.\n"
      ],
      "metadata": {
        "id": "Ag9Pu-6f4Zu0"
      }
    }
  ]
}